{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import yaml\n",
    "import unittest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = \"ml_pred_quality_unit_test.ipynb\"\n",
    "PROJECT_DIR = Path(__file__).resolve().parents[1]\n",
    "PROCESSED_DIR = \"data\\\\processed\"\n",
    "PARAMS = yaml.safe_load(open(f'{os.path.join(PROJECT_DIR)}\\\\params.yaml'))[\"train\"]\n",
    "X_TRAIN = f\"{os.path.join(PROJECT_DIR, PROCESSED_DIR)}\\\\x_train.txt\"\n",
    "Y_TRAIN = f\"{os.path.join(PROJECT_DIR, PROCESSED_DIR)}\\\\y_train.txt\"\n",
    "X_TEST = f\"{os.path.join(PROJECT_DIR, PROCESSED_DIR)}\\\\x_test.txt\"\n",
    "Y_TEST = f\"{os.path.join(PROJECT_DIR, PROCESSED_DIR)}\\\\y_test.txt\"\n",
    "CLF_OUT = \"models/rf_clf.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(np.loadtxt(X_TRAIN, delimiter=','), np.loadtxt(Y_TRAIN, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7077922077922078"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.score(np.loadtxt(X_TEST, delimiter=','), np.loadtxt(Y_TEST, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7077922077922078"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = np.loadtxt(Y_TEST, delimiter=',')\n",
    "y_predict = dt_clf.predict(np.loadtxt(X_TEST, delimiter=','))\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "roc = roc_auc_score(y_test, y_predict)\n",
    "cr = classification_report(y_predict, y_test, output_dict=True)\n",
    "cm = confusion_matrix(y_predict, y_test)\n",
    "f1 = f1_score(y_test, y_predict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6768707482993197"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80, 20],\n",
       "       [25, 29]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5631067961165048"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0': {'precision': 0.7619047619047619,\n",
       "  'recall': 0.8,\n",
       "  'f1-score': 0.7804878048780488,\n",
       "  'support': 100},\n",
       " '1.0': {'precision': 0.5918367346938775,\n",
       "  'recall': 0.5370370370370371,\n",
       "  'f1-score': 0.5631067961165048,\n",
       "  'support': 54},\n",
       " 'accuracy': 0.7077922077922078,\n",
       " 'macro avg': {'precision': 0.6768707482993197,\n",
       "  'recall': 0.6685185185185185,\n",
       "  'f1-score': 0.6717973004972768,\n",
       "  'support': 154},\n",
       " 'weighted avg': {'precision': 0.7022705185970491,\n",
       "  'recall': 0.7077922077922078,\n",
       "  'f1-score': 0.7042632953123126,\n",
       "  'support': 154}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePipeline:\n",
    "    def __init__(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.Y_test = None, None, None, None\n",
    "        self.model = None\n",
    "        self.load_dataset()\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        load the dataset\n",
    "        \"\"\"\n",
    "        self.X_train, self.X_test, = np.loadtxt(X_TRAIN, delimiter=','), np.loadtxt(X_TEST, delimiter=',')\n",
    "        self.y_train, self.y_test = np.loadtxt(Y_TRAIN, delimiter=','), np.loadtxt(Y_TEST, delimiter=',')\n",
    "\n",
    "    def train(self, algorithm=DecisionTreeClassifier(random_state=42)):\n",
    "        self.model = algorithm\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        return self.model.predict(input_data)\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "         return self.model.score(X=self.X_test, y=self.y_test)\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Helper method to run multiple pipeline methods with one call.\"\"\"\n",
    "        self.load_dataset()\n",
    "        self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModelPipeline():\n",
    "    def __init__(self):\n",
    "        self.X_test, self.Y_test = None, None\n",
    "        self.model = None\n",
    "        self.load_model()\n",
    "        self.load_dataset()\n",
    "\n",
    "    def load_model(self):\n",
    "        with (open(os.path.join(PROJECT_DIR, CLF_OUT), \"rb\")) as f:\n",
    "            self.model = pickle.load(f)\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"\n",
    "        load the dataset\n",
    "        \"\"\"\n",
    "        self.X_test = np.loadtxt(X_TEST, delimiter=',')\n",
    "        self.y_test = np.loadtxt(Y_TEST, delimiter=',')\n",
    "\n",
    "    def predict(self, input_data):\n",
    "        return self.model.predict(input_data)\n",
    "\n",
    "    def get_accuracy(self):\n",
    "         return self.model.score(X=self.X_test, y=self.y_test)\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        \"\"\"Helper method to run multiple pipeline methods with one call.\"\"\"\n",
    "        self.load_model\n",
    "        self.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestModelPredictions(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # We prepare both pipelines for use in the tests\n",
    "        self.pipeline_v1 = SimplePipeline()\n",
    "        self.pipeline_v1.run_pipeline()\n",
    "        self.pipeline_v2 = NewModelPipeline()\n",
    "        self.pipeline_v2.run_pipeline()\n",
    "    \n",
    "    def test_accuracy_higher_than_benchmark(self):\n",
    "\n",
    "        # given\n",
    "        benchmark_accuracy = .65\n",
    "\n",
    "        # predictions = self.pipeline_v1.predict(self.pipeline_v1.X_test)\n",
    "\n",
    "        # When\n",
    "        # actual_accuracy = accuracy_score(\n",
    "        #     y_true=self.pipeline_v1.y_test,\n",
    "        #     y_pred=predictions)\n",
    "\n",
    "        actual_accuracy = self.pipeline_v1.get_accuracy()\n",
    "            \n",
    "        # Then\n",
    "        print(f'model accuracy: {round(actual_accuracy, 4)}, benchmark accuracy: {benchmark_accuracy}')\n",
    "        self.assertTrue(round(actual_accuracy, 4) > benchmark_accuracy)\n",
    "    \n",
    "\n",
    "    def test_f1_score_higher_than_benchmark(self):\n",
    "        \"\"\"\n",
    "        >0.9 very good\n",
    "        0.8 - 0.9 good\n",
    "        0.5 - 0.8 ok\n",
    "        < 0.5 not good\n",
    "        \"\"\"\n",
    "        predictions = self.pipeline_v2.predict(self.pipeline_v1.X_test)\n",
    "\n",
    "        # given\n",
    "        benchmark_f1_score = 0.5\n",
    "\n",
    "        actual_f1_score = f1_score(self.pipeline_v2.y_test, predictions)\n",
    "        # Then\n",
    "        print(f'model f1: {round(actual_f1_score, 4)}, benchmark f1: {benchmark_f1_score}')\n",
    "        self.assertTrue(round(actual_f1_score, 4) > benchmark_f1_score)\n",
    "    \n",
    "\n",
    "    def test_tpr_higher_than_benchmark(self):\n",
    "\n",
    "        predictions = self.pipeline_v2.predict(self.pipeline_v2.X_test)\n",
    "\n",
    "        # given\n",
    "        benchmark_tpr_score = 0.3\n",
    "        cm = confusion_matrix(predictions, self.pipeline_v2.y_test)\n",
    "        tn,fp,fn,tp = cm.ravel()\n",
    "\n",
    "        # sensitivity, hit rate, recall, or true positive rate\n",
    "        actual_tpr = tp/(tp+fn)\n",
    "\n",
    "        # then\n",
    "        print(f\"model tpr: {round(actual_tpr, 4)}, benchmark tpr: {benchmark_tpr_score}\")\n",
    "        self.assertTrue(round(actual_tpr, 4) > benchmark_tpr_score)\n",
    "\n",
    "    \n",
    "    def test_tnr_higher_than_benchmark(self):\n",
    "\n",
    "        predictions = self.pipeline_v2.predict(self.pipeline_v2.X_test)\n",
    "\n",
    "        # given\n",
    "        benchmark_tnr_score = 0.3\n",
    "        cm = confusion_matrix(predictions, self.pipeline_v2.y_test)\n",
    "        tn,fp,fn,tp = cm.ravel()\n",
    "\n",
    "        # Specificity or true negative rate\n",
    "        actual_tnr = tn/(tn+fp)\n",
    "\n",
    "        # then\n",
    "        print(f\"model tnr: {round(actual_tnr, 4)}, benchmark tnr: {benchmark_tnr_score}\")\n",
    "        self.assertTrue(round(actual_tnr, 4) > benchmark_tnr_score)\n",
    "\n",
    "    def test_fnr_lower_than_benchmark(self):\n",
    "        \n",
    "        predictions = self.pipeline_v2.predict(self.pipeline_v2.X_test)\n",
    "\n",
    "        # given\n",
    "        benchmark_fnr_score = 0.20\n",
    "        cm = confusion_matrix(predictions, self.pipeline_v2.y_test)\n",
    "        tn,fp,fn,tp = cm.ravel()\n",
    "\n",
    "        # False negative rate\n",
    "        actual_fnr = fn/(tp+fn)\n",
    "\n",
    "        # then\n",
    "        print(f\"model fnr:{round(actual_fnr,4)}, benchmark fnr:{benchmark_fnr_score}\")\n",
    "        self.assertTrue(round(actual_fnr, 4) < benchmark_fnr_score)\n",
    "\n",
    "\n",
    "\n",
    "    def test_accuracy_compared_to_basemodel(self):\n",
    "        # when\n",
    "        v1_accuracy = self.pipeline_v1.get_accuracy()\n",
    "        v2_accuracy = self.pipeline_v2.get_accuracy()\n",
    "\n",
    "        # Then\n",
    "        # print(f'pipeline v1 accuracy: {v1_accuracy}')\n",
    "        print(f'pipeline v2 accuracy: {round(v2_accuracy,4)} >= {round(v1_accuracy, 4)} pipeline v1 accuracy')\n",
    "        self.assertTrue(v2_accuracy >= v1_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline v2 accuracy: 0.7532 >= 0.7078 pipeline v1 accuracy\n",
      "model accuracy: 0.7078, benchmark accuracy: 0.65\n",
      "model f1: 0.6042, benchmark f1: 0.5\n",
      "model fnr:0.383, benchmark fnr:0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.445s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model tnr: 0.8131, benchmark tnr: 0.3\n",
      "model tpr: 0.617, benchmark tpr: 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=0 failures=0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestModelPredictions)\n",
    "unittest.TextTestRunner(verbosity=1, stream=sys.stderr).run(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31707781077fc74384c05184f6719817e7f3ddc149af1ea4209ad95512571db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
