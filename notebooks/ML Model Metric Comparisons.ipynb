{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95f2989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232dc4a",
   "metadata": {},
   "source": [
    "## Main functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3079515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_confusion_matrix_metrics(model1, model2, y_pred1, y_pred2, y_test):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # compare confusion matrix\n",
    "    # TP, FN\n",
    "    # FP, TN\n",
    "    \n",
    "    cm_1 = confusion_matrix(y_test, y_pred1, labels=model1.classes_)\n",
    "    cm_2 = confusion_matrix(y_test, y_pred2, labels=model2.classes_)\n",
    "\n",
    "    print(cm_1)\n",
    "    print('\\n', cm_2)\n",
    "    \n",
    "    difference = np.subtract(cm_1, cm_2)\n",
    "    tp, fn = difference[0][0], difference[0][1]\n",
    "    fp, tn = difference[1][0], difference[1][1]\n",
    "    \n",
    "    print(tp, fn)\n",
    "    print(fp, tn)\n",
    "    \n",
    "    print('\\n', difference, '\\n')\n",
    "    \n",
    "    c1, c2 = fn < 0, fp < 0\n",
    "    c3, c4 = tp < 0, tn < 0\n",
    "    \n",
    "    results = {'tp':0,\n",
    "              'fp':0,\n",
    "              'fn':0,\n",
    "              'tn':0}\n",
    "    \n",
    "    # check if overall decrease\n",
    "    if all([c1, c2]):\n",
    "        print('there is an overall decrease in confusion matrix')\n",
    "        print(f'model 2 has a FN increase of {abs(fn)}')\n",
    "        print(f'model 2 has a FP increase of {abs(fp)}')\n",
    "        \n",
    "        results['fn'] = abs(fn)\n",
    "        results['fp'] = abs(fp)\n",
    "    \n",
    "    # check if overal increase    \n",
    "    elif all([c3, c4]):\n",
    "        print('there is an overall increase in confusion matrix')\n",
    "        print(f'model 2 has a TP increase of {abs(tp)}')\n",
    "        print(f'model 2 has a TN increase of {abs(tn)}')\n",
    "        \n",
    "        results['tp'] = abs(tp)\n",
    "        results['tn'] = abs(tn)\n",
    "    \n",
    "    # check if one decrease area \n",
    "    elif any([c1, c2]):\n",
    "        if c1:\n",
    "            print(f'model 2 has a FN increase of: {abs(fn)}')\n",
    "            results['fn'] = abs(fn)\n",
    "        else:\n",
    "            print(f'model 2 has a FP increase of: {abs(fp)}')\n",
    "            results['fp'] = abs(fp)\n",
    "    \n",
    "    # check if one increase area\n",
    "    elif any([c3, c4]):\n",
    "        if c3:\n",
    "            print(f'model 2 has a TP increase of: {abs(tp)}')\n",
    "            results['tp'] = abs(tp)\n",
    "        else:\n",
    "            print(f'model 2 has a TN increase of: {abs(tn)}')\n",
    "            results['tn'] = abs(tn)\n",
    "    else:\n",
    "        print('there was no confusion matrix improvement') \n",
    "        return results\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def compare_auc(model1, model2, X_test, y_test):\n",
    "    \n",
    "    ras1 = roc_auc_score(y_test, model1.predict(X_test))\n",
    "    ras2 = roc_auc_score(y_test, model2.predict(X_test))\n",
    "    \n",
    "    return ras1 - ras2\n",
    "    \n",
    "        \n",
    "def compare_classification_report(y_pred1, y_pred2, y_test):\n",
    "    \n",
    "    cr1 = classification_report(y_test, y_pred1, output_dict=True)\n",
    "    cr2 = classification_report(y_test, y_pred2, output_dict=True)\n",
    "    \n",
    "    results = {'0':{key: cr1['0'][key] - cr2['0'][key] for key in cr1['0'].keys()},\n",
    "               '1':{key: cr1['1'][key] - cr2['1'][key] for key in cr1['1'].keys()}\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "        \n",
    "    \n",
    "def model_comparison_helper(model1, model2, y_pred1, y_pred2, X_test, y_test):\n",
    "    \n",
    "    confusion_results = compare_confusion_matrix_metrics(model1, model2, y_pred1, y_pred2, y_test)\n",
    "    \n",
    "    auc_results = compare_auc(model1, model2, X_test, y_test)\n",
    "    \n",
    "    cr_results = compare_classification_report(y_pred1, y_pred2, y_test)\n",
    "    \n",
    "    print(confusion_results)\n",
    "    print(auc_results)\n",
    "    print(cr_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b9972",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "032a22df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'target']\n",
    "df = pd.read_csv(url, names=names)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5115b7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  target\n",
       "0     6   148    72    35     0  33.6  0.627   50       1\n",
       "1     1    85    66    29     0  26.6  0.351   31       0\n",
       "2     8   183    64     0     0  23.3  0.672   32       1\n",
       "3     1    89    66    23    94  28.1  0.167   21       0\n",
       "4     0   137    40    35   168  43.1  2.288   33       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858437d1",
   "metadata": {},
   "source": [
    "# Split into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d27725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,: -1].values\n",
    "y = df.loc[:,'target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6ae8f",
   "metadata": {},
   "source": [
    "# Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "436c66b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aec73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train XGBoost model\n",
    "X, y = shap.datasets.adult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f237ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:42:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "2022/04/15 08:42:22 INFO mlflow.models.evaluation.base: Evaluating the model with the default evaluator.\n",
      "pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "2022/04/15 08:42:22 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as binary dataset, positive label is True, negative label is False.\n",
      "2022/04/15 08:42:23 INFO mlflow.models.evaluation.default_evaluator: Shap explainer Tree is used.\n",
      "Unable to serialize underlying model using MLflow, will use SHAP serialization\n",
      "2022/04/15 08:42:28 WARNING mlflow.models.evaluation.default_evaluator: Log explainer failed. Reason: 'TreeEnsemble' object has no attribute 'save'\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\leopa\\\\AppData\\\\Local\\\\Temp\\\\tmpv_c8soa0\\\\confusion_matrix_on_data_adult.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-dd0ae4b3a7ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mmodel_uri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_artifact_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     result = mlflow.evaluate(\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mmodel_uri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0meval_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\site-packages\\mlflow\\models\\evaluation\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, data, targets, model_type, dataset_name, dataset_path, feature_names, evaluators, evaluator_config, custom_metrics)\u001b[0m\n\u001b[0;32m    917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_start_run_or_reuse_active_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m         return _evaluate(\n\u001b[0m\u001b[0;32m    920\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m             \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\site-packages\\mlflow\\models\\evaluation\\base.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m(model, model_type, dataset, run_id, evaluator_name_list, evaluator_name_to_conf_map, custom_metrics)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcan_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluator_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Evaluating the model with the {evaluator_name} evaluator.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             result = evaluator.evaluate(\n\u001b[0m\u001b[0;32m    636\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m                 \u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\site-packages\\mlflow\\models\\evaluation\\default_evaluator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, model, model_type, dataset, run_id, evaluator_config, custom_metrics, **kwargs)\u001b[0m\n\u001b[0;32m    907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"classifier\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mmodel_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"regressor\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_evaluate_regressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\site-packages\\mlflow\\utils\\file_utils.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, tp, val, traceback)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remove\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_remove\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    616\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\leopa\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\leopa\\\\AppData\\\\Local\\\\Temp\\\\tmpv_c8soa0\\\\confusion_matrix_on_data_adult.png'"
     ]
    }
   ],
   "source": [
    "num_examples = len(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = xgboost.XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "eval_data = X_test\n",
    "eval_data[\"label\"] = y_test\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    result = mlflow.evaluate(\n",
    "        model_uri,\n",
    "        eval_data,\n",
    "        targets=\"label\",\n",
    "        model_type=\"classifier\",\n",
    "        dataset_name=\"adult\",\n",
    "        evaluators=[\"default\"],\n",
    "    )\n",
    "\n",
    "print(f\"metrics:\\n{result.metrics}\")\n",
    "print(f\"artifacts:\\n{result.artifacts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2810b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799acae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\leopa\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b7522f578895>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0meval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0meval_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "model = xgboost.XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "eval_data = X_test\n",
    "eval_data[\"label\"] = y_test\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    model_uri = mlflow.get_artifact_uri(\"model\")\n",
    "    result = mlflow.evaluate(\n",
    "        model_uri,\n",
    "        eval_data,\n",
    "        targets=\"label\",\n",
    "        model_type=\"classifier\",\n",
    "        dataset_name=\"adult\",\n",
    "        evaluators=[\"default\"],\n",
    "    )\n",
    "\n",
    "print(f\"metrics:\\n{result.metrics}\")\n",
    "print(f\"artifacts:\\n{result.artifacts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d941193",
   "metadata": {},
   "source": [
    "## Train classifiers for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acc1da2",
   "metadata": {},
   "source": [
    "### Classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d2aaafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: \n",
      "{'criterion': 'entropy', 'max_features': 'auto', 'min_samples_leaf': 4, 'n_estimators': 256}\n",
      "Average cross-validation score for best model: 0.7899240303878449\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators':[64, 128, 256, 500, 1000],\n",
    "#           'max_depth': [4,5,6,7,8,9,10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "         'criterion' :['gini', 'entropy']}\n",
    "\n",
    "clf_rf = GridSearchCV(RandomForestClassifier(random_state=42, n_jobs=-1),param_grid=params, cv=5, refit = True)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best parameters: \\n{clf_rf.best_params_}')\n",
    "print(f'Average cross-validation score for best model: {clf_rf.best_score_}')\n",
    "\n",
    "rf_classifier = clf_rf.best_estimator_\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bba8b0",
   "metadata": {},
   "source": [
    "### Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d576f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.833 with a standard deviation of 0.0225\n"
     ]
    }
   ],
   "source": [
    "rf_classifier_2 = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf_classifier_2.fit(X_train,y_train)\n",
    "\n",
    "rf2_scores = cross_val_score(rf_classifier_2, X_train, y_train, scoring='roc_auc', cv=StratifiedKFold(n_splits=5), n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print(f'Mean ROC AUC: {round(np.mean(rf2_scores),3)} with a standard deviation of {round(np.std(rf2_scores),4)}')\n",
    "\n",
    "y_pred_2 = rf_classifier_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fdfa5d",
   "metadata": {},
   "source": [
    "## Compare classifier metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad5e3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 19]\n",
      " [20 35]]\n",
      "\n",
      " [[78 21]\n",
      " [20 35]]\n",
      "2 -2\n",
      "0 0\n",
      "\n",
      " [[ 2 -2]\n",
      " [ 0  0]] \n",
      "\n",
      "model 2 has a FN increase of: 2\n",
      "{'tp': 0, 'fp': 0, 'fn': 2, 'tn': 0}\n",
      "0.010101010101010055\n",
      "{'0': {'precision': 0.004081632653061273, 'recall': 0.02020202020202022, 'f1-score': 0.012141927913680184, 'support': 0}, '1': {'precision': 0.02314814814814814, 'recall': 0.0, 'f1-score': 0.011571204231754617, 'support': 0}}\n"
     ]
    }
   ],
   "source": [
    "model_comparison_helper(rf_classifier, rf_classifier_2, y_pred, y_pred_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1de428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use matplotlib.pyplot.matshow() to represent an correlation matrix in a new figure window\n",
    "plt.matshow(df.corr())\n",
    "\n",
    "# set the ticks\n",
    "plt.xticks(range(len(df.columns)), df.columns, rotation=90)\n",
    "plt.yticks(range(len(df.columns)), df.columns)\n",
    "\n",
    "# set the color bar\n",
    "plt.colorbar()\n",
    "\n",
    "# draw\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "columns = df.columns[:-1]\n",
    "for col in columns:\n",
    "    sub_df = df[['target', col]]\n",
    "    csq = chi2_contingency(pd.crosstab(sub_df['target'], sub_df[col]))\n",
    "    print(f'col: {col}, P-value: {csq[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
